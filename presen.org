#+title: 
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg


#+BEGIN_outline-text-1
#+BEGIN_CENTER
#+BEGIN_XLARGE
Classical Planning in a

Deep Latent Space
#+END_XLARGE

(WIP project idea)
#+END_CENTER

#+BEGIN_NOTE
#+BEGIN_ALIGNRIGHT
Made by guicho2.71828 (Masataro Asai)
#+END_ALIGNRIGHT
#+END_NOTE
#+END_outline-text-1

* Classical Planning 

_/✔/_ *Scalable, Highly-optimized solver* for complex combinatorial problems

_/✔/_ Guided by *domain-independent* heuristics

*/✘/* *Requires an explicit encoding* of the real world, written by human

* Reinforcement Learning

*Policy function* $\pi(s)\mapsto a : S \rightarrow A$ -- returns action $a$ for state $s$

Agent always follows the policy function

*Optimal Policy* $\pi^* (s)$ : a policy that gives the highest reward

Goal: *Find/learn* the best approximation of $\pi^*$

Methods: Value-iteration, Policy-iteration, TD-learning ∋ Q-learning

* Latent Space $L$ of an original state space $S$

#+BEGIN_QUOTE
Apparently very complex $S$ can be described by low-dimentional $L$
#+END_QUOTE

[[jpg:static/cicada]]

* Reinforcement Learning(RL) in Latent Space

RL in $S$ is too difficult → Apply RL to $L$ for speedup

\[L \ni y = Wx+b, x\in S\]

　

mapping 62-DOF space → 2D

[[png:static/latent-RL]]

* Deep Reinforcement Learning


* Comparison


#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN4
#+BEGIN_CENTER
*Classical Planning*
#+END_CENTER

_/✔/_ *Scalable, Highly-optimized solver* for complex combinatorial problems

_/✔/_ Guided by *domain-independent* heuristics

*/✘/* *Requires an explicit encoding* of the real world, written by human
#+END_SPAN4
#+BEGIN_SPAN4
#+BEGIN_CENTER
*Deep Reinforcement Learning*
#+END_CENTER

_/✔/_ Works on the *implicit encoding* of the real world

*/✘/* Reasoning is limited to the *1-step future* of the current state

*/✘/* guided by *instance-specific learned knowledge* (specific object, situation, goal)
#+END_SPAN4
#+END_ROW-FLUID
#+BEGIN_SPAN4
#+BEGIN_CENTER
*Deep Reinforcement Learning*
#+END_CENTER

_/✔/_ Works on the *implicit encoding* of the real world

*/✘/* Reasoning is limited to the *1-step future* of the current state

*/✘/* guided by *instance-specific learned knowledge* (specific object, situation, goal)
#+END_SPAN4
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

