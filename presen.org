#+title: 
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg


#+BEGIN_outline-text-1
#+BEGIN_CENTER
#+BEGIN_XLARGE
Classical Planning in a

Deep Latent Space
#+END_XLARGE

(WIP project idea)
#+END_CENTER

#+BEGIN_NOTE
#+BEGIN_ALIGNRIGHT
Made by guicho2.71828 (Masataro Asai)
#+END_ALIGNRIGHT
#+END_NOTE
#+END_outline-text-1

* Classical Planning 

_/✔/_ *Scalable, Highly-optimized solver* for complex combinatorial problems

_/✔/_ Guided by *domain-independent* heuristics

*/✘/* *Requires an explicit encoding* of the real world, written by human

* Reinforcement Learning

*Policy function* $\pi(s)\mapsto a : S \rightarrow A$ -- returns action $a$ for state $s$

Agent always follows the policy function

*Optimal Policy* $\pi^* (s)$ : a policy that gives the highest reward

Goal: *Find/learn* the best approximation of $\pi^*$

Methods: Value-iteration, Policy-iteration, TD-learning ∋ Q-learning

* Latent Space $L$ of an original state space $S$

#+BEGIN_QUOTE
Apparently very complex $S$ can be described by low-dimentional $L$
#+END_QUOTE

[[jpg:static/cicada]]

* Reinforcement Learning(RL) in Latent Space (e.g. Luck IROS14, AAAI16)

RL in $S$ is too difficult → Apply RL to $L$ for speedup

\[x\in S, y \in L: \ y = f(x) \]

　

mapping 62-DOF space → 2D

[[png:static/latent-RL]]

* Underlying belief:

#+BEGIN_QUOTE
The real world is apparently complex, but in *almost all cases* they can be described by *only a few parameters*.
#+END_QUOTE

* Manifold Hypothesis

[[png:static/manifold]]

* Neural Network

+ A framework for learning a *function* that maps input $x$ to output $y$

+ Perceptron w/ $>2$ layers can learn arbitrary function

[[png:static/nn]]

* Autoencoder

#+BEGIN_CENTER
Unsupervised learning method which learns to 

*compress S* into *L* and *decompress back to S*
#+END_CENTER

→ able to obtain the latent space $L$

[[png:static/autoenc]]

* Deep Q Learning

RL + deep learning

* Comparison


#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN4
#+BEGIN_CENTER
*Classical Planning*
#+END_CENTER

_/✔/_ *Scalable, Highly-optimized solver* for complex combinatorial problems

_/✔/_ Guided by *domain-independent* heuristics

*/✘/* *Requires an explicit encoding* of the real world, written by human
#+END_SPAN4
#+BEGIN_SPAN4
#+BEGIN_CENTER
*Deep Reinforcement Learning*
#+END_CENTER

_/✔/_ Works on the *implicit encoding* of the real world

*/✘/* Reasoning is limited to the *1-step future* of the current state

*/✘/* guided by *instance-specific learned knowledge* (specific object, situation, goal)
#+END_SPAN4
#+END_ROW-FLUID
#+BEGIN_SPAN4
#+BEGIN_CENTER
*Deep Reinforcement Learning*
#+END_CENTER

_/✔/_ Works on the *implicit encoding* of the real world

*/✘/* Reasoning is limited to the *1-step future* of the current state

*/✘/* guided by *instance-specific learned knowledge* (specific object, situation, goal)
#+END_SPAN4
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

